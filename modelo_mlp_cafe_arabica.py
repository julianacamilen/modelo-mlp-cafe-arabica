# -*- coding: utf-8 -*-
"""modelo-mlp-cafe-arabica.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f-j7eJ8rAe9IRoB0tXo9FkeW46hJjsLQ
"""

# Importação de bibliotecas

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.callbacks import EarlyStopping
from sklearn.metrics import mean_absolute_error, mean_squared_error
import math

# Conexão entre o Google Colab e o Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Criação de função para o pré-processamento dos dados
# A execução de todas as funções será realizada na última célula

def load_and_preprocess_data(filepath, start_date, end_date):
    # Leitura do conjunto de dados
    df = pd.read_csv("/content/drive/MyDrive/CEPEA.csv")

    # Renomeação das colunas de preço
    df.rename(columns={
        'valor_reais': 'preco_reais',
        'valor_dolares': 'preco_dolares'
    }, inplace=True)

    # Conversão da coluna 'data' para o formato datetime
    df['data'] = pd.to_datetime(df['data'], format='%d/%m/%Y', dayfirst=True, errors='coerce')

    # Filtragem dos dados para o período desejado
    df = df[(df['data'] >= start_date) & (df['data'] <= end_date)]

    # Ordenação ascendente dos dados pela coluna 'data'
    df.sort_values(by='data', ascending=True, inplace=True)

    # Redefinição do índice do conjunto de dados
    df.reset_index(drop=True, inplace=True)

    return df

# Visualização dos dados
def plot_data(df):
    sns.set_theme(style="whitegrid")
    plt.figure(figsize=(16, 8))
    sns.lineplot(x="data", y="preco_reais", data=df, color="#8c94d7", linewidth=2)
    plt.title("Preços de Café Arábica no Brasil", fontsize=16, fontweight="bold", color="#333333")
    plt.xlabel("Ano", fontsize=14, color="#333333")
    plt.ylabel("Preço (R$)", fontsize=14, color="#333333")
    plt.xticks(rotation=45, fontsize=12)
    plt.yticks(fontsize=12)
    plt.grid(visible=True, color="#dddddd", linestyle="--", linewidth=0.7)
    plt.show()

# Preparação dos dados para o MLP
def prepare_data(df, column, window_size, train_split=0.8):
    # Extração dos dados da coluna desejada ('preco_reais')
    price = df[[column]].values

    # Normalização dos dados em uma escala 0-1
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_data = scaler.fit_transform(price)

    # Divisão dos dados para treinamento (80%) e teste (20%) do modelo
    train_size = int(len(scaled_data) * train_split)
    train_data = scaled_data[:train_size]
    test_data = scaled_data[train_size - window_size:]

    # Criação das sequências de dados para o MLP
    def create_sequences(data, window_size):
        X, y = [], []
        for i in range(window_size, len(data)):
            X.append(data[i - window_size:i, 0])  # Coletar 'window_size' passos de dados para X
            y.append(data[i, 0])  # O próximo valor (target) para y
        return np.array(X), np.array(y)

    # Criação sequências para dados de treinamento e teste
    X_train, y_train = create_sequences(train_data, window_size)
    X_test, y_test = create_sequences(test_data, window_size)

    # Remodelação dos dados para o formato 2D conforme exigido pelo MLP
    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1]))
    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1]))

    return X_train, y_train, X_test, y_test, scaler

# Construção do modelo MLP
def build_mlp_model(input_shape):
    model = Sequential([
        Dense(64, activation='relu', input_shape=(window_size,)),
        Dropout(0.2),
        Dense(32, activation='relu'),
        Dropout(0.2),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    return model

# Definição de EarlyStopping
early_stop = EarlyStopping(
    monitor='val_loss',     # Pode ser 'loss' se não usar validação
    patience=5,             # Para de treinar se não melhorar por 5 épocas
    restore_best_weights=True  # Volta para o melhor modelo
)

# Avaliação do modelo MLP
def evaluate_model(y_test, y_pred, scaler):
    # Transformação inversa dos valores normalizados
    y_test = scaler.inverse_transform(y_test.reshape(-1, 1))
    y_pred = scaler.inverse_transform(y_pred.reshape(-1, 1))

    mae = mean_absolute_error(y_test, y_pred)
    rmse = math.sqrt(mean_squared_error(y_test, y_pred))
    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100

    print(f"MAE: {mae:.2f}")
    print(f"MAPE: {mape:.2f}%")
    print(f"RMSE: {rmse:.2f}")

    return mae, mape, rmse

# Visualização das previsões
def plot_predictions(df, train_size, y_test, y_pred):
    plt.figure(figsize=(16, 8))
    train = df[:train_size]
    valid = df[train_size:].copy()
    valid["Previsões"] = scaler.inverse_transform(y_pred.reshape(-1, 1))

    plt.plot(df["data"], df["preco_reais"], label="Dados reais", color="#8c94d7")
    plt.plot(valid["data"], valid["preco_reais"], label="Validação", color="#0a4479")
    plt.plot(valid["data"], valid["Previsões"], label="Dados previstos", color="#f1c232")
    plt.title("Previsão de Preços de Café Arábica no Brasil", fontsize=16)
    plt.xlabel("Ano", fontsize=14)
    plt.ylabel("Preço (R$)", fontsize=14)
    plt.legend()
    plt.grid()
    plt.show()

# Fluxo principal
# Aplicação das funções

if __name__ == "__main__":
    filepath = "/content/drive/MyDrive/CEPEA.csv"
    df = load_and_preprocess_data(filepath, '2015-01-01', '2025-01-01')

    plot_data(df)

    window_size = 60
    X_train, y_train, X_test, y_test, scaler = prepare_data(df, "preco_reais", window_size)

    model = build_mlp_model((X_train.shape[1],))
    model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stop], verbose=1)

    y_pred = model.predict(X_test)
    evaluate_model(y_test, y_pred, scaler)

    train_size = int(len(df) * 0.8)
    plot_predictions(df, train_size, y_test, y_pred)